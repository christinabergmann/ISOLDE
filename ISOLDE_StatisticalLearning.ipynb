{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Modelling Tutorial - Simulating Infant Statistical Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This IPython notebook contains exercise 1 of the Computational Modelling tutorial at ISOLDE 2018 in Potsdam. \n",
    "\n",
    "- What does the model do?\n",
    "\n",
    "This model tests the hypothesis that infants use transitional probabilities to learn where word boundaries lies within unsegmented, continuous speech. The model will be written in Python, but the same ideas could also be implemented using a different programming language.\n",
    "\n",
    "- What do we need?\n",
    "\n",
    "\n",
    "1. Reading in the data from the corpus, by opening it, reading it in line by line and counting the syllables and syllable pairs. \n",
    "2. Computing the probabilities for the bigrams (syllable pairs) and unigrams (single syllables)\n",
    "3. Testing the model by comparing the average probability of words to the average probability of non-words\n",
    "\n",
    "- But first:\n",
    "\n",
    "Let's learn some Python!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-tutorial: Python basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note for using Python: \n",
    "\n",
    "Blocks of code that belong together must by indented the same way, so be careful not to mix indention using spaces and tabs as this might look the same. If your code does not compile, checking the indenting is a good thing to check at first.\n",
    "\n",
    "### Variable-types\n",
    "\n",
    "#### Numbers\n",
    "\n",
    "Variables containing numbers are made by assigning a value to a variable name, for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_sandwiches = 4\n",
    "\n",
    "price_per_sandwich = 3.50\n",
    "\n",
    "price = number_of_sandwiches * price_per_sandwich\n",
    "\n",
    "price "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text\n",
    "\n",
    "Variables containing text are called strings, and they are made by assigning the text (within quotation marks) to a variable name, for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type_of_sandwich = \"tomato and cheese\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lists\n",
    "When you want to store multiple bits of information in one variable, you could use a list. Lists are made by using square brackets [] and separating everything you store in the list with a comma.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empty_order = []\n",
    "\n",
    "order = [4,\"tomato_and_cheese\", 3.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionaries\n",
    "Another way of storing information is using dictionaries. In a dictionary, you can store combinations of a 'key' and value. Keys are usually string-variables, but the value can be any kind of variable-type. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making an empty dictionary is done by using curly brackets {}:\n",
    "\n",
    "employee_numbers = {}\n",
    "\n",
    "#You can add a key-value pair to the dictionary: \n",
    "employee_numbers['Hank'] = 6758\n",
    "employee_numbers['Sarah'] = 5664\n",
    "\n",
    "#And asks for the value linked to a key: \n",
    "\n",
    "Sarahs_employee_number = employee_numbers['Sarah']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control-flow\n",
    "\n",
    "#### If-else - statements\n",
    "If else - statements can be used when you only want something to happen in certain cases, and not in others. For instance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thank you for your purchase!\n"
     ]
    }
   ],
   "source": [
    "credit = 40.65\n",
    "\n",
    "if credit < price:\n",
    "    print('not enough credit, try paying in a different way')\n",
    "else:\n",
    "    credit -= price\n",
    "    print('thank you for your purchase!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### For-loops\n",
    "With a for-loop you can iterate over a sequence (either a list or a string) and perform a certain computation for each item within the sequence. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Hank !\n",
      "Hello Sarah !\n",
      "Hello Joe !\n",
      "19.5\n"
     ]
    }
   ],
   "source": [
    "names = ['Hank', 'Sarah', 'Joe']\n",
    "\n",
    "for name in names:\n",
    "    print(\"Hello \"+ name + \" !\")\n",
    "    \n",
    "#Or, another example:\n",
    "prices = [3.5,5.6,8.0,2.4]\n",
    "total_price = 0\n",
    "\n",
    "for i in range(0,len(prices)):\n",
    "    total_price += prices[i]\n",
    "    \n",
    "print(total_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function that can read in the data from the corpusfile. \n",
    "\n",
    "First, we need to create a list to store the results. \n",
    "\n",
    "Then, we open the file for reading, signalled by 'r', and read it in line by line. For each line of in the corpus we remove the end-of-line symbol and add the remained syllable to the list of results. \n",
    "\n",
    "Finally, we return the list with syllables so that it can be used by the rest of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    \"\"\" read corpus from '\\n'-delimited text file\n",
    "    returns a list of syllables \"\"\"\n",
    "    \n",
    "    #Write your Python-code here\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    # open the file for reading and loop over the lines\n",
    "    for line in open(filename, 'r'):\n",
    "        syll = line.strip()\n",
    "        result.append(syll)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'tu',\n",
       " 'pi',\n",
       " 'ro',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti',\n",
       " 'go',\n",
       " 'la',\n",
       " 'bu',\n",
       " 'bi',\n",
       " 'da',\n",
       " 'ku',\n",
       " 'pa',\n",
       " 'do',\n",
       " 'ti']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is how we want to use this little routine:\n",
    "corpusfile = 'saffran_corpus.cor'\n",
    "corpus = read_corpus(corpusfile)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 2: Processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to process the corpus and compute the probabilities for the syllables and syllable-pairs. We split this functionality into three parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts of the syllables or syllable-pairs can be stored in dictionaries. Then, we go through the list of syllables to add the syllables and syllable-pairs to the dictionaries, or update their respective counts if they are already in the dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus(list_of_syllables):\n",
    "    \"\"\" extract count of uni- & bigram occurrences from sequence\n",
    "    of syllables in list_of_syllables \"\"\"\n",
    "    \n",
    "    unigram_dict = {}\n",
    "    bigram_dict = {}\n",
    "    \n",
    "    for syllable_index in range(len(list_of_syllables)-1):\n",
    "        unigram = list_of_syllables[syllable_index]\n",
    "        if unigram in unigram_dict:\n",
    "            unigram_dict[unigram] += 1\n",
    "        else:\n",
    "            unigram_dict[unigram] = 1\n",
    "            \n",
    "        bigram = (list_of_syllables[syllable_index], list_of_syllables[syllable_index +1])\n",
    "        if bigram in bigram_dict:\n",
    "            bigram_dict[bigram] += 1\n",
    "        else: \n",
    "            bigram_dict[bigram] = 1\n",
    "    \n",
    "    unigram = list_of_syllables[-1]\n",
    "    if unigram in unigram_dict:\n",
    "        unigram_dict[unigram] += 1\n",
    "    else:\n",
    "        unigram_dict[unigram] = 1\n",
    "\n",
    "    # return the dictionaries with the unigram and bigram counts\n",
    "    return unigram_dict, bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bi': 44,\n",
       " 'bu': 45,\n",
       " 'da': 44,\n",
       " 'do': 40,\n",
       " 'go': 45,\n",
       " 'ku': 44,\n",
       " 'la': 45,\n",
       " 'pa': 40,\n",
       " 'pi': 51,\n",
       " 'ro': 51,\n",
       " 'ti': 40,\n",
       " 'tu': 51}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_dict, bigram_dict = process_corpus(corpus)\n",
    "unigram_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of a bigram (syll_1, syll_2) can be computed by divided the count of both syllables togethers by the count of the first syllable alone.  So, you compute how often the first syllable is followed by the second, opposed to by any other syllable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimated_bigram_probability(bigram, unigram_dict, bigram_dict):\n",
    "    \"\"\" estimate the probability of bigram (= (syll_1,syll_2)) by:\n",
    "    (count (syll_1,syll_2)) / (count syll_1)\n",
    "    \"\"\"\n",
    "    count = 0.\n",
    "    \n",
    "    if bigram in bigram_dict:\n",
    "        count = bigram_dict[bigram]\n",
    "    \n",
    "    prob = count / unigram_dict[bigram[0]]\n",
    "    \n",
    "    #return the estimated bigram probability \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of a sequence of syllables can be computed by going through the sequence and multiplying all the estimated bigram probabilities of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimated_sequence_probability(list_of_syllables, unigram_dict, bigram_dict):\n",
    "    \"\"\" estimate probability of sequence of syllables,\n",
    "    represented as a list \"\"\"\n",
    "    \n",
    "    # set probability to 1 initially\n",
    "    prob = 1.\n",
    "\n",
    "    # loop over sequence indices\n",
    "    for syll_idx in range(len(list_of_syllables) - 1):\n",
    "        # form bigram from subsequent syllables\n",
    "        bigram = (list_of_syllables[syll_idx], list_of_syllables[syll_idx + 1])\n",
    "        \n",
    "        # multiply previous probability with probability of this bigram\n",
    "        prob= prob * estimated_bigram_probability(bigram, unigram_dict, bigram_dict)\n",
    "\n",
    "    # return the estimated probability of the entire sequence\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the model we need the experimental test-phase stimuli from the Saffran-study. These are given below. \n",
    "\n",
    "We want to compare the average probability for word to the average probability for non-words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-17-60c4703161f3>, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-60c4703161f3>\"\u001b[1;36m, line \u001b[1;32m56\u001b[0m\n\u001b[1;33m    sum_words = 0\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def test_model(unigram_dict, bigram_dict):\n",
    "    \"\"\" test the model on saffran's words and non-words\n",
    "    \"\"\"\n",
    "    \n",
    "    # the words and non-words from saffran\n",
    "    words = [['tu','pi','ro'],\n",
    "             ['go','la','bu'],\n",
    "             ['bi','da','ku'],\n",
    "             ['pa','do','ti']]\n",
    "    non_words = [['da','pi','ku'],\n",
    "                 ['ti','la','do']]\n",
    "\n",
    "    # calculate the sum of the probabilities of the words\n",
    "    sum_words = 0\n",
    "    for word in words:\n",
    "        sum_words += estimated_sequence_probability(word, unigram_dict, bigram_dict)\n",
    "\n",
    "    # divide by the number of words to get the average\n",
    "    average_word = sum_words / len(words)\n",
    "\n",
    "    # idem for the non-words\n",
    "    sum_non_words = 0\n",
    "    for non_word in non_words:\n",
    "        sum_non_words += estimated_sequence_probability(non_word, unigram_dict, bigram_dict)\n",
    "    # divide by the number of words to get the average        \n",
    "    average_non_word = sum_non_words / len(non_words)\n",
    "\n",
    "    print('Average probability for words:', average_word)\n",
    "    print('Average probability for non-words:', average_non_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can complete a whole run through the model. Which commands do you need to type in below in what order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average probability for words: 1.0\n",
      "Average probability for non-words: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Let's see whether everything works. Don't worry if you get an error message, that is normal even for experienced programmers.\n",
    "\n",
    "test_model(unigram_dict, bigram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'non': 1, 'e': 6, 'da': 6, 'me': 17, 'scen': 1, 'de': 3, 're': 4, 'dal': 3, 'lo': 6, 'in': 5, 'u': 3, 'na': 6, 'fu': 18, 'ti': 3, 'le': 4, 'ga': 6, 'a': 4, 'pi': 3, 'Tor': 1, 'no': 5, 'ca': 6, 'sa': 6, 'la': 16, 'ta': 12, 'con': 1, 'bi': 6, 'ci': 8, 'di': 7, 'ma': 2, 'tu': 1, 'il': 7, 'ver': 4, 'se': 2, 'ro': 3, 'por': 2, 'te': 2, 'pres': 1, 'so': 7, 'mes': 1, 'vi': 4, 'zio': 1, 'lu': 1, 'i': 3, 'gi': 3, 'do': 2, 'col': 2, 'ten': 2, 'ri': 3, 'o': 7, 'del': 6, 'an': 2, 'co': 5, 'ros': 1, 'si': 3, 'va': 2, 'nu': 2, 'lin': 1, 'ge': 1, 'che': 3, 'to': 5, 'scor': 1, 'sog': 1, 'li': 2, 'ber': 1, 'rat': 1, 'quan': 1, 'tem': 1, 'pes': 1, 'mi': 2, 'sot': 1, 'al': 1, 'om': 1, 'bro': 1, 'su': 1, 'ra': 1, 'sem': 1, 'bra': 1, 'ce': 1, 'stel': 1, 'fer': 1, 'sul': 1, 'zi': 1}\n",
      "{('non', 'e'): 1, ('e', 'da'): 1, ('da', 'me'): 1, ('me', 'scen'): 1, ('scen', 'de'): 1, ('de', 're'): 1, ('re', 'dal'): 1, ('dal', 'me'): 1, ('me', 'lo'): 6, ('lo', 'in'): 1, ('in', 'u'): 1, ('u', 'na'): 3, ('na', 'fu'): 2, ('fu', 'ti'): 1, ('ti', 'le'): 1, ('le', 'fu'): 1, ('fu', 'ga'): 6, ('ga', 'dal'): 1, ('dal', 'le'): 1, ('le', 'a'): 1, ('a', 'pi'): 1, ('pi', 'Tor'): 1, ('Tor', 'no'): 1, ('no', 'a'): 1, ('a', 'ca'): 2, ('ca', 'sa'): 6, ('sa', 'dal'): 1, ('dal', 'la'): 1, ('la', 'fu'): 3, ('fu', 'ta'): 1, ('ta', 'con'): 1, ('con', 'la'): 1, ('la', 'bi'): 3, ('bi', 'ci'): 6, ('ci', 'pi'): 1, ('pi', 'e'): 1, ('e', 'na'): 1, ('na', 'di'): 1, ('di', 'me'): 2, ('me', 'le'): 1, ('le', 'ma'): 1, ('ma', 'tu'): 1, ('tu', 're'): 1, ('re', 'il'): 1, ('il', 'me'): 2, ('lo', 'e'): 1, ('e', 'di'): 1, ('di', 'ver'): 1, ('ver', 'se'): 1, ('se', 'bi'): 1, ('ci', 'fu'): 1, ('fu', 'ro'): 2, ('ro', 'no'): 1, ('no', 'por'): 1, ('por', 'ta'): 1, ('ta', 'te'): 1, ('te', 'pres'): 1, ('pres', 'so'): 1, ('so', 'la'): 2, ('la', 'mes'): 1, ('mes', 'ci'): 1, ('ci', 'ta'): 1, ('ta', 'di'): 1, ('di', 'vi'): 1, ('vi', 'no'): 1, ('no', 'zio'): 1, ('zio', 'lu'): 1, ('lu', 'i'): 1, ('i', 'gi'): 1, ('gi', 'me'): 1, ('me', 'do'): 1, ('do', 'e'): 1, ('e', 'in'): 1, ('in', 'fu'): 1, ('ga', 'col'): 1, ('col', 'la'): 2, ('ci', 'ver'): 2, ('ver', 'de'): 1, ('de', 'vi'): 1, ('vi', 'fu'): 2, ('fu', 'le'): 1, ('le', 'ta'): 1, ('ta', 'de'): 1, ('de', 'i'): 1, ('i', 'ten'): 1, ('ten', 'ta'): 1, ('ta', 'ti'): 1, ('ti', 'vi'): 1, ('vi', 'di'): 1, ('di', 'fu'): 1, ('ga', 'in'): 1, ('in', 'bi'): 1, ('ver', 'so'): 2, ('so', 'il'): 1, ('il', 'ri'): 1, ('ri', 'fu'): 1, ('fu', 'gi'): 1, ('gi', 'o'): 1, ('o', 'del'): 1, ('del', 'me'): 2, ('lo', 'an'): 1, ('an', 'ti'): 1, ('ti', 'co'): 1, ('co', 'il'): 1, ('il', 'fu'): 1, ('ro', 'me'): 1, ('me', 'ro'): 1, ('ro', 'ros'): 1, ('ros', 'si'): 1, ('si', 'te'): 1, ('te', 'me'): 1, ('me', 'va'): 1, ('va', 'di'): 1, ('di', 'an'): 1, ('an', 'da'): 1, ('da', 're'): 1, ('re', 'in'): 1, ('in', 'gi'): 1, ('gi', 'ta'): 1, ('ta', 'col'): 1, ('ci', 'nu'): 1, ('nu', 'o'): 2, ('o', 'va'): 1, ('va', 'da'): 1, ('da', 'ri'): 1, ('ri', 'o'): 2, ('o', 'fu'): 1, ('fu', 'lin'): 1, ('lin', 'ge'): 1, ('ge', 'nu'): 1, ('o', 'che'): 1, ('che', 'por'): 1, ('por', 'to'): 1, ('to', 'u'): 1, ('na', 'bi'): 1, ('ci', 'a'): 1, ('sa', 'il'): 1, ('me', 'se'): 1, ('se', 'scor'): 1, ('scor', 'so'): 1, ('so', 'u'): 1, ('ga', 'da'): 2, ('da', 'ca'): 2, ('sa', 'e'): 1, ('e', 'il'): 1, ('il', 'sog'): 1, ('sog', 'no'): 1, ('no', 'del'): 1, ('del', 'la'): 3, ('la', 'to'): 1, ('to', 'pi'): 1, ('pi', 'na'): 1, ('na', 'me'): 1, ('me', 'la'): 1, ('la', 'ver'): 1, ('la', 'li'): 1, ('li', 'ber'): 1, ('ber', 'ta'): 1, ('ta', 'il'): 2, ('il', 'rat'): 1, ('rat', 'to'): 1, ('to', 'me'): 1, ('me', 'co'): 1, ('co', 'ten'): 1, ('ten', 'to'): 1, ('to', 'la'): 1, ('sa', 'quan'): 1, ('quan', 'do'): 1, ('do', 'vi'): 1, ('fu', 'la'): 1, ('la', 'tem'): 1, ('tem', 'pes'): 1, ('pes', 'ta'): 1, ('il', 'mi'): 1, ('mi', 'ci'): 1, ('ci', 'o'): 1, ('o', 're'): 1, ('re', 'fu'): 1, ('fu', 'so'): 1, ('so', 'me'): 1, ('me', 'di'): 1, ('di', 'ta'): 1, ('ta', 'in'): 1, ('in', 'ca'): 1, ('sa', 'o'): 1, ('o', 'di'): 1, ('me', 'na'): 1, ('na', 'la'): 1, ('la', 'co'): 2, ('co', 'da'): 1, ('da', 'sot'): 1, ('sot', 'to'): 1, ('to', 'al'): 1, ('al', 'me'): 1, ('lo', 'om'): 1, ('om', 'bro'): 1, ('bro', 'so'): 1, ('so', 'su'): 1, ('su', 'i'): 1, ('i', 'ra'): 1, ('ra', 'mi'): 1, ('mi', 'del'): 1, ('lo', 'che'): 2, ('che', 'sem'): 1, ('sem', 'bra'): 1, ('bra', 'no'): 1, ('no', 'fu'): 1, ('fu', 'si'): 1, ('si', 'ce'): 1, ('ce', 'la'): 1, ('la', 'ca'): 1, ('sa', 'del'): 1, ('del', 'fu'): 1, ('fu', 'co'): 1, ('co', 'so'): 1, ('so', 'li'): 1, ('li', 'ta'): 1, ('ta', 'ri'): 1, ('o', 'la'): 1, ('ga', 'del'): 1, ('la', 'stel'): 1, ('stel', 'la'): 1, ('co', 'me'): 1, ('me', 'ta'): 1, ('ta', 'si'): 1, ('si', 'e'): 1, ('e', 'fer'): 1, ('fer', 'ma'): 1, ('ma', 'ta'): 1, ('ta', 'sul'): 1, ('sul', 'me'): 1, ('che', 'fu'): 1, ('fu', 'del'): 1, ('la', 'zi'): 1, ('zi', 'a'): 1}\n",
      "Average probability for words: 0.3431372549019608\n",
      "Average probability for non-words: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "corpusfile_italian=\"Pelucci3B.cor\"\n",
    "corpus_italian = read_corpus(corpusfile_italian)\n",
    "\n",
    "# Now, as before, we get unigrams and bigrams, use the print() command to inspect them.\n",
    "unigram_dict_italian, bigram_dict_italian = process_corpus(corpus_italian)\n",
    "print(unigram_dict_italian)\n",
    "print(bigram_dict_italian)\n",
    "\n",
    "# Now we just need to adapt the test_model routine. We change the name to not overwrite the previous function\n",
    "def test_model_italian(unigram_dict, bigram_dict):\n",
    "    \"\"\" test the model on saffran's words and non-words\n",
    "    \"\"\"\n",
    "    \n",
    "    # the words and non-words from Pelucci et al., experiment 3\n",
    "    words = [['me', 'lo'],\n",
    "             ['fu', 'ga']]\n",
    "    non_words = [['bi', 'ci'],\n",
    "                 ['ca', 'sa']]\n",
    "\n",
    "    # calculate the sum of the probabilities of the words\n",
    "    sum_words = 0\n",
    "    for word in words:\n",
    "        sum_words += estimated_sequence_probability(word, unigram_dict, bigram_dict)\n",
    "\n",
    "    # divide by the number of words to get the average\n",
    "    average_word = sum_words / len(words)\n",
    "\n",
    "    # idem for the non-words\n",
    "    sum_non_words = 0\n",
    "    for non_word in non_words:\n",
    "        sum_non_words += estimated_sequence_probability(non_word, unigram_dict, bigram_dict)\n",
    "    # divide by the number of words to get the average        \n",
    "    average_non_word = sum_non_words / len(non_words)\n",
    "\n",
    "    print('Average probability for words:', average_word)\n",
    "    print('Average probability for non-words:', average_non_word)\n",
    "\n",
    "\n",
    "# Now test this:\n",
    "\n",
    "test_model_italian(unigram_dict_italian, bigram_dict_italian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
